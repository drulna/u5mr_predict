{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Input, BatchNormalization, Dropout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard,  ReduceLROnPlateau, CSVLogger\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 72080\n",
      "Total Records:  72080\n",
      "Total Variables/Attributes:  54\n"
     ]
    }
   ],
   "source": [
    "clean_data = pd.read_csv('data/clean_data.tsv', sep='\\t', encoding='utf-8')\n",
    "clean_data = clean_data.astype(str)\n",
    "print('Total records:', len(clean_data))\n",
    "y = np.load('data/labels.npy')\n",
    "X = np.array(clean_data)\n",
    "print('Total Records: ', X.shape[0])\n",
    "print('Total Variables/Attributes: ', X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "for i in range (X.shape[1]):\n",
    "    le = LabelEncoder()\n",
    "    X[:,i] = le.fit_transform(X[:,i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le_y = LabelEncoder()\n",
    "#y = le_y.fit_transform(y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = Input(shape=(X.shape[1],))\n",
    "x = Dense(100, activation='relu') (ip)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(50, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "out = Dense(1) (x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[ip], outputs=[out])\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.004, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#optimizer = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.2, nesterov=True)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "logCallback = CSVLogger('logs/train_log.csv', separator=',', append=False)\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=0, mode='min')\n",
    "checkpoint = ModelCheckpoint('models/DNN.h5', monitor='val_loss', save_weights_only=True, verbose=1, save_best_only=True, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, cooldown=0, min_lr=0.0000000001, verbose=0)\n",
    "\n",
    "callbacks_list = [logCallback, earlyStopping, reduce_lr, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54060 samples, validate on 18020 samples\n",
      "Epoch 1/200\n",
      " - 2s - loss: 70.2562 - acc: 0.0705 - val_loss: 81.9675 - val_acc: 0.0918\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 81.96754, saving model to models/DNN.h5\n",
      "Epoch 2/200\n",
      " - 1s - loss: 63.0070 - acc: 0.0552 - val_loss: 71.4725 - val_acc: 0.1463\n",
      "\n",
      "Epoch 00002: val_loss improved from 81.96754 to 71.47246, saving model to models/DNN.h5\n",
      "Epoch 3/200\n",
      " - 1s - loss: 62.8224 - acc: 0.0549 - val_loss: 67.6038 - val_acc: 0.1498\n",
      "\n",
      "Epoch 00003: val_loss improved from 71.47246 to 67.60384, saving model to models/DNN.h5\n",
      "Epoch 4/200\n",
      " - 1s - loss: 61.7608 - acc: 0.0574 - val_loss: 64.4074 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00004: val_loss improved from 67.60384 to 64.40737, saving model to models/DNN.h5\n",
      "Epoch 5/200\n",
      " - 1s - loss: 61.2767 - acc: 0.0583 - val_loss: 62.6238 - val_acc: 0.0726\n",
      "\n",
      "Epoch 00005: val_loss improved from 64.40737 to 62.62379, saving model to models/DNN.h5\n",
      "Epoch 6/200\n",
      " - 1s - loss: 62.0622 - acc: 0.0607 - val_loss: 70.0197 - val_acc: 0.0690\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 62.62379\n",
      "Epoch 7/200\n",
      " - 1s - loss: 62.5345 - acc: 0.0586 - val_loss: 66.1275 - val_acc: 0.0372\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 62.62379\n",
      "Epoch 8/200\n",
      " - 1s - loss: 62.2491 - acc: 0.0603 - val_loss: 62.4275 - val_acc: 0.0400\n",
      "\n",
      "Epoch 00008: val_loss improved from 62.62379 to 62.42750, saving model to models/DNN.h5\n",
      "Epoch 9/200\n",
      " - 1s - loss: 61.9239 - acc: 0.0606 - val_loss: 62.9951 - val_acc: 0.0819\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 62.42750\n",
      "Epoch 10/200\n",
      " - 1s - loss: 61.9504 - acc: 0.0616 - val_loss: 60.8073 - val_acc: 0.0588\n",
      "\n",
      "Epoch 00010: val_loss improved from 62.42750 to 60.80733, saving model to models/DNN.h5\n",
      "Epoch 11/200\n",
      " - 1s - loss: 61.8678 - acc: 0.0591 - val_loss: 61.3432 - val_acc: 0.0425\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 60.80733\n",
      "Epoch 12/200\n",
      " - 1s - loss: 61.6021 - acc: 0.0617 - val_loss: 60.9679 - val_acc: 0.0472\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 60.80733\n",
      "Epoch 13/200\n",
      " - 1s - loss: 61.4597 - acc: 0.0606 - val_loss: 60.5675 - val_acc: 0.0506\n",
      "\n",
      "Epoch 00013: val_loss improved from 60.80733 to 60.56747, saving model to models/DNN.h5\n",
      "Epoch 14/200\n",
      " - 1s - loss: 61.4267 - acc: 0.0613 - val_loss: 60.5765 - val_acc: 0.0601\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 60.56747\n",
      "Epoch 15/200\n",
      " - 1s - loss: 61.3261 - acc: 0.0615 - val_loss: 60.4357 - val_acc: 0.0572\n",
      "\n",
      "Epoch 00015: val_loss improved from 60.56747 to 60.43570, saving model to models/DNN.h5\n",
      "Epoch 16/200\n",
      " - 1s - loss: 61.5455 - acc: 0.0633 - val_loss: 60.3215 - val_acc: 0.0620\n",
      "\n",
      "Epoch 00016: val_loss improved from 60.43570 to 60.32149, saving model to models/DNN.h5\n",
      "Epoch 17/200\n",
      " - 1s - loss: 61.3448 - acc: 0.0623 - val_loss: 60.3588 - val_acc: 0.0640\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 60.32149\n",
      "Epoch 18/200\n",
      " - 1s - loss: 61.4925 - acc: 0.0619 - val_loss: 60.2864 - val_acc: 0.0613\n",
      "\n",
      "Epoch 00018: val_loss improved from 60.32149 to 60.28637, saving model to models/DNN.h5\n",
      "Epoch 19/200\n",
      " - 1s - loss: 61.6109 - acc: 0.0611 - val_loss: 60.3222 - val_acc: 0.0592\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 60.28637\n",
      "Epoch 20/200\n",
      " - 1s - loss: 61.4643 - acc: 0.0630 - val_loss: 60.2974 - val_acc: 0.0602\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 60.28637\n",
      "Epoch 21/200\n",
      " - 1s - loss: 61.4188 - acc: 0.0615 - val_loss: 60.2764 - val_acc: 0.0603\n",
      "\n",
      "Epoch 00021: val_loss improved from 60.28637 to 60.27645, saving model to models/DNN.h5\n",
      "Epoch 22/200\n",
      " - 1s - loss: 61.4681 - acc: 0.0607 - val_loss: 60.3101 - val_acc: 0.0604\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 60.27645\n",
      "Epoch 23/200\n",
      " - 1s - loss: 61.4956 - acc: 0.0599 - val_loss: 60.2958 - val_acc: 0.0613\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 60.27645\n",
      "Epoch 24/200\n",
      " - 1s - loss: 61.4596 - acc: 0.0618 - val_loss: 60.3076 - val_acc: 0.0608\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 60.27645\n",
      "Epoch 25/200\n",
      " - 1s - loss: 61.5584 - acc: 0.0616 - val_loss: 60.2696 - val_acc: 0.0612\n",
      "\n",
      "Epoch 00025: val_loss improved from 60.27645 to 60.26964, saving model to models/DNN.h5\n",
      "Epoch 26/200\n",
      " - 1s - loss: 61.6230 - acc: 0.0616 - val_loss: 60.2450 - val_acc: 0.0611\n",
      "\n",
      "Epoch 00026: val_loss improved from 60.26964 to 60.24504, saving model to models/DNN.h5\n",
      "Epoch 27/200\n",
      " - 1s - loss: 61.2730 - acc: 0.0612 - val_loss: 60.2770 - val_acc: 0.0607\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 60.24504\n",
      "Epoch 28/200\n",
      " - 1s - loss: 61.4394 - acc: 0.0606 - val_loss: 60.2973 - val_acc: 0.0614\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 60.24504\n",
      "Epoch 29/200\n",
      " - 1s - loss: 61.4208 - acc: 0.0600 - val_loss: 60.3264 - val_acc: 0.0615\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 60.24504\n",
      "Epoch 30/200\n",
      " - 1s - loss: 61.5832 - acc: 0.0620 - val_loss: 60.3187 - val_acc: 0.0612\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 60.24504\n",
      "Epoch 31/200\n",
      " - 1s - loss: 61.6016 - acc: 0.0630 - val_loss: 60.2844 - val_acc: 0.0608\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 60.24504\n",
      "Epoch 32/200\n",
      " - 1s - loss: 61.3960 - acc: 0.0637 - val_loss: 60.2588 - val_acc: 0.0607\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 60.24504\n",
      "Epoch 33/200\n",
      " - 1s - loss: 61.5179 - acc: 0.0611 - val_loss: 60.2524 - val_acc: 0.0603\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 60.24504\n",
      "Epoch 34/200\n",
      " - 1s - loss: 61.4315 - acc: 0.0614 - val_loss: 60.2477 - val_acc: 0.0610\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 60.24504\n",
      "Epoch 35/200\n",
      " - 1s - loss: 61.4600 - acc: 0.0622 - val_loss: 60.2870 - val_acc: 0.0619\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 60.24504\n",
      "Epoch 36/200\n",
      " - 1s - loss: 61.5636 - acc: 0.0640 - val_loss: 60.2935 - val_acc: 0.0611\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 60.24504\n",
      "Epoch 37/200\n",
      " - 1s - loss: 61.4827 - acc: 0.0608 - val_loss: 60.2417 - val_acc: 0.0613\n",
      "\n",
      "Epoch 00037: val_loss improved from 60.24504 to 60.24168, saving model to models/DNN.h5\n",
      "Epoch 38/200\n",
      " - 1s - loss: 61.4367 - acc: 0.0622 - val_loss: 60.2782 - val_acc: 0.0609\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 60.24168\n",
      "Epoch 39/200\n",
      " - 1s - loss: 61.3268 - acc: 0.0613 - val_loss: 60.3114 - val_acc: 0.0605\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 60.24168\n",
      "Epoch 40/200\n",
      " - 1s - loss: 61.4599 - acc: 0.0609 - val_loss: 60.3068 - val_acc: 0.0614\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 60.24168\n",
      "Epoch 41/200\n",
      " - 1s - loss: 61.4248 - acc: 0.0620 - val_loss: 60.2760 - val_acc: 0.0610\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 60.24168\n",
      "Epoch 42/200\n",
      " - 1s - loss: 61.4478 - acc: 0.0613 - val_loss: 60.2876 - val_acc: 0.0606\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 60.24168\n",
      "Epoch 43/200\n",
      " - 1s - loss: 61.4023 - acc: 0.0614 - val_loss: 60.3150 - val_acc: 0.0614\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 60.24168\n",
      "Epoch 44/200\n",
      " - 1s - loss: 61.4118 - acc: 0.0601 - val_loss: 60.2941 - val_acc: 0.0607\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 60.24168\n",
      "Epoch 45/200\n",
      " - 1s - loss: 61.4959 - acc: 0.0616 - val_loss: 60.2592 - val_acc: 0.0613\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 60.24168\n",
      "Epoch 46/200\n",
      " - 1s - loss: 61.6074 - acc: 0.0601 - val_loss: 60.2389 - val_acc: 0.0605\n",
      "\n",
      "Epoch 00046: val_loss improved from 60.24168 to 60.23892, saving model to models/DNN.h5\n",
      "Epoch 47/200\n",
      " - 1s - loss: 61.6354 - acc: 0.0623 - val_loss: 60.2985 - val_acc: 0.0608\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 60.23892\n",
      "Epoch 48/200\n",
      " - 1s - loss: 61.4824 - acc: 0.0624 - val_loss: 60.2913 - val_acc: 0.0610\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 60.23892\n",
      "Epoch 49/200\n",
      " - 1s - loss: 61.3842 - acc: 0.0605 - val_loss: 60.3082 - val_acc: 0.0615\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 60.23892\n",
      "Epoch 50/200\n",
      " - 1s - loss: 61.5553 - acc: 0.0614 - val_loss: 60.2737 - val_acc: 0.0611\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 60.23892\n",
      "Epoch 51/200\n",
      " - 1s - loss: 61.5359 - acc: 0.0614 - val_loss: 60.2491 - val_acc: 0.0605\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 60.23892\n",
      "Epoch 52/200\n",
      " - 1s - loss: 61.3964 - acc: 0.0613 - val_loss: 60.2906 - val_acc: 0.0613\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 60.23892\n",
      "Epoch 53/200\n",
      " - 1s - loss: 61.3420 - acc: 0.0621 - val_loss: 60.3522 - val_acc: 0.0607\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 60.23892\n",
      "Epoch 54/200\n",
      " - 1s - loss: 61.4412 - acc: 0.0617 - val_loss: 60.3159 - val_acc: 0.0607\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 60.23892\n",
      "Epoch 55/200\n",
      " - 1s - loss: 61.4899 - acc: 0.0601 - val_loss: 60.3304 - val_acc: 0.0604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00055: val_loss did not improve from 60.23892\n",
      "Epoch 56/200\n",
      " - 1s - loss: 61.5784 - acc: 0.0610 - val_loss: 60.2960 - val_acc: 0.0615\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 60.23892\n",
      "Epoch 57/200\n",
      " - 1s - loss: 61.4658 - acc: 0.0608 - val_loss: 60.2797 - val_acc: 0.0618\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 60.23892\n",
      "Epoch 58/200\n",
      " - 1s - loss: 61.5379 - acc: 0.0619 - val_loss: 60.2732 - val_acc: 0.0607\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 60.23892\n",
      "Epoch 59/200\n",
      " - 1s - loss: 61.5582 - acc: 0.0611 - val_loss: 60.2853 - val_acc: 0.0612\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 60.23892\n",
      "Epoch 60/200\n",
      " - 1s - loss: 61.4430 - acc: 0.0597 - val_loss: 60.3625 - val_acc: 0.0612\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 60.23892\n",
      "Epoch 61/200\n",
      " - 1s - loss: 61.5419 - acc: 0.0618 - val_loss: 60.3391 - val_acc: 0.0612\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 60.23892\n",
      "Epoch 62/200\n",
      " - 1s - loss: 61.6213 - acc: 0.0612 - val_loss: 60.2414 - val_acc: 0.0606\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 60.23892\n",
      "Epoch 63/200\n",
      " - 1s - loss: 61.5610 - acc: 0.0604 - val_loss: 60.2761 - val_acc: 0.0610\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 60.23892\n",
      "Epoch 64/200\n",
      " - 1s - loss: 61.3757 - acc: 0.0613 - val_loss: 60.2773 - val_acc: 0.0609\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 60.23892\n",
      "Epoch 65/200\n",
      " - 1s - loss: 61.4394 - acc: 0.0623 - val_loss: 60.2607 - val_acc: 0.0608\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 60.23892\n",
      "Epoch 66/200\n",
      " - 1s - loss: 61.4510 - acc: 0.0614 - val_loss: 60.2964 - val_acc: 0.0610\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 60.23892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1882e3a1748>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "         validation_data=(X_test, y_test),\n",
    "                       batch_size=256,\n",
    "                       epochs=200,\n",
    "                       verbose=2,\n",
    "                       shuffle=True,\n",
    "                       #class_weight = class_weights,\n",
    "                       callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
